{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Classifica√ß√£o de Spam usando MLP (Perceptron Multicamadas)\n",
        "\n",
        "## Objetivo\n",
        "Treinar uma rede neural MLP para classificar mensagens como **Spam** ou **N√£o Spam (Ham)**\n",
        "\n",
        "### Especifica√ß√µes:\n",
        "- **Dataset**: SMS/Email Spam\n",
        "- **Features**: TF-IDF (5000 palavras)\n",
        "- **Valida√ß√£o**: 10-fold Cross-validation\n",
        "- **M√©tricas**: Acur√°cia, Precis√£o, Recall, F1-Score, Matriz de Confus√£o\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Importa√ß√£o de Bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manipula√ß√£o de dados\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Pr√©-processamento de texto\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Modelo MLP\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# M√©tricas\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "\n",
        "# Visualiza√ß√£o\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configura√ß√µes visuais\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Ignorar warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Bibliotecas importadas com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Carregamento e Explora√ß√£o dos Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar o dataset\n",
        "df = pd.read_csv('archive/combined_data.csv')\n",
        "\n",
        "print(\"üìä Informa√ß√µes do Dataset:\")\n",
        "print(f\"Total de mensagens: {len(df)}\")\n",
        "print(f\"\\nPrimeiras linhas:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar valores nulos\n",
        "print(\"üîç Valores nulos:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Remover valores nulos se existirem\n",
        "df = df.dropna()\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset limpo: {len(df)} mensagens\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribui√ß√£o das classes\n",
        "print(\"üìä Distribui√ß√£o das Classes:\")\n",
        "print(df['label'].value_counts())\n",
        "print(f\"\\nPropor√ß√£o:\")\n",
        "print(df['label'].value_counts(normalize=True) * 100)\n",
        "\n",
        "# Visualizar distribui√ß√£o\n",
        "plt.figure(figsize=(8, 5))\n",
        "df['label'].value_counts().plot(kind='bar', color=['#2ecc71', '#e74c3c'])\n",
        "plt.title('Distribui√ß√£o das Classes', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Classe (0=Ham, 1=Spam)', fontsize=12)\n",
        "plt.ylabel('Quantidade', fontsize=12)\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Prepara√ß√£o dos Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separar features (X) e target (y)\n",
        "X = df['text']\n",
        "y = df['label']\n",
        "\n",
        "print(f\"üìù Total de mensagens: {len(X)}\")\n",
        "print(f\"üéØ Total de labels: {len(y)}\")\n",
        "print(f\"\\n‚úÖ Dados preparados!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4Ô∏è‚É£ Extra√ß√£o de Features com TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurar TF-IDF Vectorizer\n",
        "# max_features=5000: Limita ao vocabul√°rio de 5000 palavras mais frequentes\n",
        "# max_df=0.8: Ignora palavras que aparecem em mais de 80% dos documentos\n",
        "# min_df=2: Ignora palavras que aparecem em menos de 2 documentos\n",
        "\n",
        "print(\"‚öôÔ∏è Configurando TF-IDF Vectorizer...\")\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    max_df=0.8,\n",
        "    min_df=2,\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2)  # Unigramas e bigramas\n",
        ")\n",
        "\n",
        "print(\"üîÑ Transformando textos em features TF-IDF...\")\n",
        "X_tfidf = tfidf.fit_transform(X)\n",
        "\n",
        "print(f\"\\n‚úÖ Features TF-IDF criadas!\")\n",
        "print(f\"üìä Dimens√µes da matriz: {X_tfidf.shape}\")\n",
        "print(f\"   - {X_tfidf.shape[0]} mensagens\")\n",
        "print(f\"   - {X_tfidf.shape[1]} features (palavras/bigramas)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ Divis√£o dos Dados (Hold-out para teste final)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dividir em treino e teste (80% treino, 20% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_tfidf, y, \n",
        "    test_size=0.2, \n",
        "    random_state=42,\n",
        "    stratify=y  # Mant√©m a propor√ß√£o das classes\n",
        ")\n",
        "\n",
        "print(\"üìä Divis√£o dos Dados:\")\n",
        "print(f\"   - Treino: {X_train.shape[0]} mensagens ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"   - Teste:  {X_test.shape[0]} mensagens ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"\\n‚úÖ Dados divididos!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6Ô∏è‚É£ Cria√ß√£o e Treinamento do Modelo MLP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurar o MLP Classifier\n",
        "print(\"ü§ñ Criando modelo MLP...\\n\")\n",
        "\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(100, 50),  # 2 camadas ocultas: 100 e 50 neur√¥nios\n",
        "    activation='relu',             # Fun√ß√£o de ativa√ß√£o ReLU\n",
        "    solver='adam',                 # Otimizador Adam\n",
        "    max_iter=200,                  # M√°ximo de itera√ß√µes\n",
        "    random_state=42,\n",
        "    early_stopping=True,           # Para quando n√£o houver melhora\n",
        "    validation_fraction=0.1,       # 10% dos dados de treino para valida√ß√£o\n",
        "    verbose=True                   # Mostrar progresso\n",
        ")\n",
        "\n",
        "print(\"üéØ Configura√ß√µes do MLP:\")\n",
        "print(f\"   - Camadas ocultas: {mlp.hidden_layer_sizes}\")\n",
        "print(f\"   - Fun√ß√£o de ativa√ß√£o: {mlp.activation}\")\n",
        "print(f\"   - Otimizador: {mlp.solver}\")\n",
        "print(f\"   - Early stopping: {mlp.early_stopping}\")\n",
        "print(f\"\\n‚è≥ Treinando o modelo...\\n\")\n",
        "\n",
        "# Treinar o modelo\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\n‚úÖ Modelo treinado com sucesso!\")\n",
        "print(f\"üìà Itera√ß√µes realizadas: {mlp.n_iter_}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7Ô∏è‚É£ Avalia√ß√£o com 10-Fold Cross-Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîÑ Realizando 10-Fold Cross-Validation...\\n\")\n",
        "print(\"‚è≥ Isso pode demorar alguns minutos...\\n\")\n",
        "\n",
        "# Realizar cross-validation com m√∫ltiplas m√©tricas\n",
        "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    mlp, \n",
        "    X_train, \n",
        "    y_train, \n",
        "    cv=10,\n",
        "    scoring=scoring,\n",
        "    return_train_score=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Cross-Validation completo!\\n\")\n",
        "print(\"=\"*60)\n",
        "print(\"üìä RESULTADOS DO 10-FOLD CROSS-VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for metric in scoring:\n",
        "    train_scores = cv_results[f'train_{metric}']\n",
        "    test_scores = cv_results[f'test_{metric}']\n",
        "    \n",
        "    print(f\"\\n{metric.upper()}:\")\n",
        "    print(f\"   Treino: {train_scores.mean():.4f} (¬± {train_scores.std():.4f})\")\n",
        "    print(f\"   Valida√ß√£o: {test_scores.mean():.4f} (¬± {test_scores.std():.4f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar resultados do Cross-Validation\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.suptitle('Resultados do 10-Fold Cross-Validation', fontsize=16, fontweight='bold')\n",
        "\n",
        "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "metrics_keys = ['accuracy', 'precision', 'recall', 'f1']\n",
        "\n",
        "for idx, (ax, metric_name, metric_key) in enumerate(zip(axes.flat, metrics_names, metrics_keys)):\n",
        "    train_scores = cv_results[f'train_{metric_key}']\n",
        "    test_scores = cv_results[f'test_{metric_key}']\n",
        "    \n",
        "    folds = np.arange(1, 11)\n",
        "    \n",
        "    ax.plot(folds, train_scores, 'o-', label='Treino', linewidth=2, markersize=6)\n",
        "    ax.plot(folds, test_scores, 's-', label='Valida√ß√£o', linewidth=2, markersize=6)\n",
        "    \n",
        "    ax.axhline(test_scores.mean(), color='red', linestyle='--', \n",
        "               label=f'M√©dia Val: {test_scores.mean():.4f}', alpha=0.7)\n",
        "    \n",
        "    ax.set_xlabel('Fold', fontsize=11)\n",
        "    ax.set_ylabel(metric_name, fontsize=11)\n",
        "    ax.set_title(f'{metric_name} por Fold', fontsize=12, fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.set_xticks(folds)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8Ô∏è‚É£ Avalia√ß√£o no Conjunto de Teste\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fazer predi√ß√µes no conjunto de teste\n",
        "print(\"üîÆ Fazendo predi√ß√µes no conjunto de teste...\\n\")\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Calcular todas as m√©tricas\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üéØ M√âTRICAS NO CONJUNTO DE TESTE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n‚ú® Acur√°cia:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"‚ú® Precis√£o:  {precision:.4f} ({precision*100:.2f}%)\")\n",
        "print(f\"‚ú® Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
        "print(f\"‚ú® F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Relat√≥rio de classifica√ß√£o detalhado\n",
        "print(\"\\nüìã RELAT√ìRIO DE CLASSIFICA√á√ÉO DETALHADO\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Ham (N√£o Spam)', 'Spam']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9Ô∏è‚É£ Matriz de Confus√£o\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular matriz de confus√£o\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"üìä Matriz de Confus√£o:\")\n",
        "print(cm)\n",
        "print(f\"\\nInterpreta√ß√£o:\")\n",
        "print(f\"   - Verdadeiros Negativos (Ham correto): {cm[0, 0]}\")\n",
        "print(f\"   - Falsos Positivos (Ham previsto como Spam): {cm[0, 1]}\")\n",
        "print(f\"   - Falsos Negativos (Spam previsto como Ham): {cm[1, 0]}\")\n",
        "print(f\"   - Verdadeiros Positivos (Spam correto): {cm[1, 1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar matriz de confus√£o\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "disp = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm,\n",
        "    display_labels=['Ham (N√£o Spam)', 'Spam']\n",
        ")\n",
        "\n",
        "disp.plot(cmap='Blues', ax=ax, values_format='d', colorbar=True)\n",
        "plt.title('Matriz de Confus√£o - Classifica√ß√£o de Spam', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîü Visualiza√ß√£o das M√©tricas Finais\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparar m√©tricas Cross-Validation vs Teste\n",
        "metrics_comparison = {\n",
        "    'M√©trica': ['Acur√°cia', 'Precis√£o', 'Recall', 'F1-Score'],\n",
        "    'Cross-Validation (m√©dia)': [\n",
        "        cv_results['test_accuracy'].mean(),\n",
        "        cv_results['test_precision'].mean(),\n",
        "        cv_results['test_recall'].mean(),\n",
        "        cv_results['test_f1'].mean()\n",
        "    ],\n",
        "    'Teste Final': [accuracy, precision, recall, f1]\n",
        "}\n",
        "\n",
        "df_comparison = pd.DataFrame(metrics_comparison)\n",
        "print(\"\\nüìä COMPARA√á√ÉO: Cross-Validation vs Teste Final\\n\")\n",
        "print(df_comparison.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gr√°fico de barras comparativo\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "x = np.arange(len(df_comparison['M√©trica']))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax.bar(x - width/2, df_comparison['Cross-Validation (m√©dia)'], \n",
        "               width, label='Cross-Validation (10-fold)', alpha=0.8)\n",
        "bars2 = ax.bar(x + width/2, df_comparison['Teste Final'], \n",
        "               width, label='Teste Final', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('M√©tricas', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Compara√ß√£o de M√©tricas: Cross-Validation vs Teste Final', \n",
        "             fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(df_comparison['M√©trica'])\n",
        "ax.legend(fontsize=11)\n",
        "ax.set_ylim([0, 1.05])\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.3f}',\n",
        "                ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£1Ô∏è‚É£ Testando o Modelo com Exemplos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fun√ß√£o para testar novas mensagens\n",
        "def predict_spam(message):\n",
        "    \"\"\"\n",
        "    Prediz se uma mensagem √© spam ou n√£o\n",
        "    \"\"\"\n",
        "    # Transformar a mensagem usando o TF-IDF j√° treinado\n",
        "    message_tfidf = tfidf.transform([message])\n",
        "    \n",
        "    # Fazer predi√ß√£o\n",
        "    prediction = mlp.predict(message_tfidf)[0]\n",
        "    probability = mlp.predict_proba(message_tfidf)[0]\n",
        "    \n",
        "    result = \"SPAM üö´\" if prediction == 1 else \"HAM (N√£o Spam) ‚úÖ\"\n",
        "    confidence = probability[prediction] * 100\n",
        "    \n",
        "    print(f\"Mensagem: {message}\")\n",
        "    print(f\"Predi√ß√£o: {result}\")\n",
        "    print(f\"Confian√ßa: {confidence:.2f}%\")\n",
        "    print(f\"Probabilidades: Ham={probability[0]:.3f}, Spam={probability[1]:.3f}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "# Testar com exemplos\n",
        "print(\"\\nüß™ TESTANDO O MODELO COM EXEMPLOS\\n\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "exemplos = [\n",
        "    \"Congratulations! You won a free iPhone! Click here to claim now!\",\n",
        "    \"Hey, are we still meeting for lunch tomorrow?\",\n",
        "    \"URGENT: Your account will be closed. Verify now to avoid suspension!\",\n",
        "    \"Hi mom, I'll be home late tonight. Don't wait for dinner.\",\n",
        "    \"Get rich quick! Make $5000 per day working from home!\"\n",
        "]\n",
        "\n",
        "for exemplo in exemplos:\n",
        "    predict_spam(exemplo)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£2Ô∏è‚É£ Resumo Final do Projeto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"üìù RESUMO FINAL DO PROJETO\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüéØ Objetivo: Classifica√ß√£o de Spam usando MLP\")\n",
        "print(f\"\\nüìä Dataset:\")\n",
        "print(f\"   - Total de mensagens: {len(df):,}\")\n",
        "print(f\"   - Mensagens Ham: {(y == 0).sum():,}\")\n",
        "print(f\"   - Mensagens Spam: {(y == 1).sum():,}\")\n",
        "print(f\"\\nüîß Pr√©-processamento:\")\n",
        "print(f\"   - Extra√ß√£o de features: TF-IDF\")\n",
        "print(f\"   - Vocabul√°rio: 5000 palavras/bigramas\")\n",
        "print(f\"   - Stop words: Removidas (ingl√™s)\")\n",
        "print(f\"\\nü§ñ Modelo MLP:\")\n",
        "print(f\"   - Arquitetura: {mlp.hidden_layer_sizes}\")\n",
        "print(f\"   - Fun√ß√£o de ativa√ß√£o: {mlp.activation}\")\n",
        "print(f\"   - Otimizador: {mlp.solver}\")\n",
        "print(f\"   - Itera√ß√µes: {mlp.n_iter_}\")\n",
        "print(f\"\\nüìà Valida√ß√£o:\")\n",
        "print(f\"   - M√©todo: 10-Fold Cross-Validation\")\n",
        "print(f\"   - Acur√°cia m√©dia: {cv_results['test_accuracy'].mean():.4f} (¬± {cv_results['test_accuracy'].std():.4f})\")\n",
        "print(f\"\\n‚ú® Resultados no Teste Final:\")\n",
        "print(f\"   - Acur√°cia:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"   - Precis√£o:  {precision:.4f} ({precision*100:.2f}%)\")\n",
        "print(f\"   - Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
        "print(f\"   - F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(\"\\n‚úÖ Projeto conclu√≠do com sucesso!\")\n",
        "print(\"üé• Pronto para o v√≠deo explicativo!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
